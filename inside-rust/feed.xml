<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
    <generator uri="https://blog.rust-lang.org/inside-rust/" version="0.1.0">Inside Rust Blog</generator>
    <link href="https://blog.rust-lang.org/inside-rust/feed.xml" rel="self" type="application/atom+xml" />
    <link href="https://blog.rust-lang.org/inside-rust/" rel="alternate" type="text/html" />
    <id>https://blog.rust-lang.org/inside-rust/</id>
    <title>Inside Rust Blog</title>
    <subtitle>Want to follow along with Rust development? Curious how you might get involved? Take a look!</subtitle>
    <author>
        <name>Maintained by the Rust Teams.</name>
        <uri>https://github.com/rust-lang/blog.rust-lang.org/</uri>
    </author>
    <updated>2020-11-19T14:40:50+00:00</updated>

    
    <entry>
        <title>1.48.0 pre-release testing</title>
        <link rel="alternate" href="https://blog.rust-lang.org/inside-rust/2020/11/16/1.48.0-prerelease.html" type="text/html" title="1.48.0 pre-release testing" />
        <published>2020-11-16T00:00:00+00:00</published>
        <updated>2020-11-16T00:00:00+00:00</updated>
        <id>https://blog.rust-lang.org/inside-rust/2020/11/16/1.48.0-prerelease.html</id>
        <content type="html" xml:base="https://blog.rust-lang.org/inside-rust/2020/11/16/1.48.0-prerelease.html">&lt;p&gt;The 1.48.0 pre-release is ready for testing. The release is scheduled for this
Thursday, November 19th. &lt;a href&#x3D;&quot;https://github.com/rust-lang/rust/blob/stable/RELEASES.md#version-1480-2020-11-19&quot;&gt;Release notes can be found here.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You can try it out locally by running:&lt;/p&gt;
&lt;pre&gt;&lt;code class&#x3D;&quot;language-plain&quot;&gt;RUSTUP_DIST_SERVER&#x3D;https://dev-static.rust-lang.org rustup update stable
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The index is &lt;a href&#x3D;&quot;https://dev-static.rust-lang.org/dist/2020-11-16/index.html&quot;&gt;https://dev-static.rust-lang.org/dist/2020-11-16/index.html&lt;/a&gt;. You
can leave feedback on the &lt;a href&#x3D;&quot;https://internals.rust-lang.org/t/rust-1-48-0-pre-release-testing/13401&quot;&gt;internals thread&lt;/a&gt;.&lt;/p&gt;
</content>

        <author>
            <name>Pietro Albini</name>
        </author>
    </entry>
    
    <entry>
        <title>Using rustc_codegen_cranelift for debug builds</title>
        <link rel="alternate" href="https://blog.rust-lang.org/inside-rust/2020/11/15/Using-rustc_codegen_cranelift.html" type="text/html" title="Using rustc_codegen_cranelift for debug builds" />
        <published>2020-11-15T00:00:00+00:00</published>
        <updated>2020-11-15T00:00:00+00:00</updated>
        <id>https://blog.rust-lang.org/inside-rust/2020/11/15/Using-rustc_codegen_cranelift.html</id>
        <content type="html" xml:base="https://blog.rust-lang.org/inside-rust/2020/11/15/Using-rustc_codegen_cranelift.html">&lt;h2&gt;&lt;a href&#x3D;&quot;#what-is-rustc_codegen_cranelift&quot; aria-hidden&#x3D;&quot;true&quot; class&#x3D;&quot;anchor&quot; id&#x3D;&quot;what-is-rustc_codegen_cranelift&quot;&gt;&lt;/a&gt;What is &lt;code&gt;rustc_codegen_cranelift&lt;/code&gt;?&lt;/h2&gt;
&lt;p&gt;&lt;a href&#x3D;&quot;https://github.com/bjorn3/rustc_codegen_cranelift&quot;&gt;&lt;code&gt;rustc_codegen_cranelift&lt;/code&gt;&lt;/a&gt;, or just &lt;code&gt;cg_clif&lt;/code&gt; for short, is a new experimental
codegen backend for the Rust compiler. The existing backend is LLVM, which is very
good at producing fast, highly optimized code, but is not very good at
compiling code quickly. &lt;code&gt;cg_clif&lt;/code&gt;, which uses the &lt;a href&#x3D;&quot;https://github.com/bytecodealliance/wasmtime/tree/main/cranelift#cranelift-code-generator&quot;&gt;Cranelift&lt;/a&gt; project, would
provide a fast backend which greatly improves compile times, at the cost of
performing very few optimizations. This is a great fit for debug builds, and the hope is
that &lt;code&gt;cg_clif&lt;/code&gt; will eventually be the default backend in debug mode.&lt;/p&gt;
&lt;h2&gt;&lt;a href&#x3D;&quot;#what-is-the-progress-of-using-rustc_codegen_cranelift-for-debug-builds&quot; aria-hidden&#x3D;&quot;true&quot; class&#x3D;&quot;anchor&quot; id&#x3D;&quot;what-is-the-progress-of-using-rustc_codegen_cranelift-for-debug-builds&quot;&gt;&lt;/a&gt;What is the progress of using &lt;code&gt;rustc_codegen_cranelift&lt;/code&gt; for debug builds?&lt;/h2&gt;
&lt;p&gt;There has been a &lt;a href&#x3D;&quot;https://forge.rust-lang.org/compiler/mcp.html&quot;&gt;Major Change Proposal&lt;/a&gt; open for some time for making
&lt;code&gt;cg_clif&lt;/code&gt; part of the main Rust repository. Recently, &lt;a href&#x3D;&quot;https://github.com/rust-lang/compiler-team/issues/270&quot;&gt;the MCP was
accepted&lt;/a&gt; and the compiler team &lt;a href&#x3D;&quot;https://github.com/rust-lang/rust/pull/77975&quot;&gt;merged&lt;/a&gt;
&lt;code&gt;rustc_cranelift_codegen&lt;/code&gt; &lt;a href&#x3D;&quot;https://github.com/rust-lang/rust/pull/77975&quot;&gt;into the main Rust git repository&lt;/a&gt;.
&lt;code&gt;cg_clif&lt;/code&gt; is not yet distributed with &lt;code&gt;rustup&lt;/code&gt;, but this means you can now
build it from source in-tree!&lt;/p&gt;
&lt;h2&gt;&lt;a href&#x3D;&quot;#how-do-i-use-rustc_codegen_cranelift&quot; aria-hidden&#x3D;&quot;true&quot; class&#x3D;&quot;anchor&quot; id&#x3D;&quot;how-do-i-use-rustc_codegen_cranelift&quot;&gt;&lt;/a&gt;How do I use &lt;code&gt;rustc_codegen_cranelift&lt;/code&gt;?&lt;/h2&gt;
&lt;p&gt;In this section, I&#x27;ll walk through step-by-step how to build the new backend from source, then use it on your own projects. All code is copy/paste-able, and each step is explained.&lt;/p&gt;
&lt;p&gt;First, let&#x27;s build &lt;code&gt;cg_clif&lt;/code&gt; from source.&lt;/p&gt;
&lt;pre&gt;&lt;code class&#x3D;&quot;language-sh&quot;&gt;$ git clone https://github.com/bjorn3/rustc_codegen_cranelift.git
$ ./prepare.sh
$ ./build.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we can start using it to compile a project. For demonstration purposes,
I&#x27;ll be be using &lt;code&gt;cargo&lt;/code&gt;, but you can use any Rust project supported by
&lt;code&gt;cg_clif&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd ..
$ git clone https://github.com/rust-lang/cargo/
$ cd cargo
$ ../rustc_codegen_cranelift/build/cargo.sh build
...
    Finished dev [unoptimized + debuginfo] target(s) in 49.93s
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It works! For comparison, let&#x27;s see how long the equivalent LLVM backend would
take.&lt;/p&gt;
&lt;pre&gt;&lt;code class&#x3D;&quot;language-sh&quot;&gt;$ rustup install nightly-2020-10-31
$ cargo +nightly-2020-10-31 build
...
    Finished dev [unoptimized + debuginfo] target(s) in 54.64s
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;LLVM takes a full 5 seconds longer for a full build. Next, let&#x27;s try incremental builds:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ git apply &amp;lt;&amp;lt;EOF
diff --git a/src/cargo/lib.rs b/src/cargo/lib.rs
index bccb41121..703afa754 100644
--- a/src/cargo/lib.rs
+++ b/src/cargo/lib.rs
@@ -36,8 +36,8 @@ use anyhow::Error;
 use log::debug;
 use std::fmt;
 
-pub use crate::util::errors::{InternalError, VerboseError};
 pub use crate::util::{CargoResult, CliError, CliResult, Config};
+pub use crate::util::errors::{InternalError, VerboseError};
 
 pub const CARGO_ENV: &amp;amp;str &#x3D; &amp;quot;CARGO&amp;quot;;
EOF
$ ../rustc_codegen_cranelift/build/cargo.sh build
    Finished dev [unoptimized + debuginfo] target(s) in 7.98s
$ cargo +nightly-2020-10-31 build
   Compiling cargo v0.50.0 (/home/joshua/cargo)
    Finished dev [unoptimized + debuginfo] target(s) in 5.48s
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;LLVM is actually &lt;em&gt;faster&lt;/em&gt; here: &lt;code&gt;serde_derive&lt;/code&gt; took longer to run under cranelift, since it wasn&#x27;t as optimized. Under cranelift it takes ~14% percent of the time, while under LLVM it takes less than 3%.&lt;/p&gt;
&lt;h2&gt;&lt;a href&#x3D;&quot;#building-in-tree&quot; aria-hidden&#x3D;&quot;true&quot; class&#x3D;&quot;anchor&quot; id&#x3D;&quot;building-in-tree&quot;&gt;&lt;/a&gt;Building in-tree&lt;/h2&gt;
&lt;p&gt;This section is mostly for compiler hackers, but feel free to follow along even
if you&#x27;re just interested! The reason this isn&#x27;t the recommended way to build
&lt;code&gt;cg_clif&lt;/code&gt; is because the Rust compiler takes a very long time to build.&lt;/p&gt;
&lt;p&gt;First, download the Rust repository.&lt;/p&gt;
&lt;pre&gt;&lt;code class&#x3D;&quot;language-console&quot;&gt;git clone https://github.com/rust-lang/rust
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let&#x27;s set up the build system to use &lt;code&gt;cg_clif&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class&#x3D;&quot;language-text&quot;&gt;$ cat &amp;gt; config.toml &amp;lt;&amp;lt;EOF
[rust]
codegen-backends &#x3D; [&amp;quot;cranelift&amp;quot;]
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, let&#x27;s run the build. This can take a long time, over a half-hour in some cases.&lt;/p&gt;
&lt;pre&gt;&lt;code class&#x3D;&quot;language-console&quot;&gt;./x.py build
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a href&#x3D;&quot;#how-can-i-help&quot; aria-hidden&#x3D;&quot;true&quot; class&#x3D;&quot;anchor&quot; id&#x3D;&quot;how-can-i-help&quot;&gt;&lt;/a&gt;How can I help?&lt;/h2&gt;
&lt;p&gt;You don&#x27;t need to be a compiler developer to help improve &lt;code&gt;cg_clif&lt;/code&gt;!  The best
way you can help is by testing &lt;code&gt;cg_clif&lt;/code&gt; on different Rust crates across the
ecosystem.  Just while writing this article, I found &lt;a href&#x3D;&quot;https://github.com/bjorn3/rustc_codegen_cranelift/issues/1102&quot;&gt;two&lt;/a&gt;
&lt;a href&#x3D;&quot;https://github.com/bjorn3/rustc_codegen_cranelift/issues/1101&quot;&gt;bugs&lt;/a&gt;, so there&#x27;s plenty of work left to be done. Please report any bugs you find
to the &lt;a href&#x3D;&quot;https://github.com/bjorn3/rustc_codegen_cranelift/issues/new&quot;&gt;&lt;code&gt;rustc_codegen_cranelift&lt;/code&gt; git repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In the future, we hope to distribute &lt;code&gt;cg_clif&lt;/code&gt; with Rustup, and if it matures sufficiently, eventually make it the default backend for debug builds.&lt;/p&gt;
</content>

        <author>
            <name>Joshua Nelson</name>
        </author>
    </entry>
    
    <entry>
        <title>Source-based code coverage in nightly</title>
        <link rel="alternate" href="https://blog.rust-lang.org/inside-rust/2020/11/12/source-based-code-coverage.html" type="text/html" title="Source-based code coverage in nightly" />
        <published>2020-11-12T00:00:00+00:00</published>
        <updated>2020-11-12T00:00:00+00:00</updated>
        <id>https://blog.rust-lang.org/inside-rust/2020/11/12/source-based-code-coverage.html</id>
        <content type="html" xml:base="https://blog.rust-lang.org/inside-rust/2020/11/12/source-based-code-coverage.html">&lt;p&gt;Support has landed in the nightly compiler for source-based code coverage,
and we want your help testing it!&lt;/p&gt;
&lt;h1&gt;&lt;a href&#x3D;&quot;#what-is-source-based-code-coverage-exactly&quot; aria-hidden&#x3D;&quot;true&quot; class&#x3D;&quot;anchor&quot; id&#x3D;&quot;what-is-source-based-code-coverage-exactly&quot;&gt;&lt;/a&gt;What is &lt;em&gt;source-based&lt;/em&gt; code coverage, exactly?&lt;/h1&gt;
&lt;p&gt;You may already be familiar with code coverage, which shows you which lines
of code execute. Code coverage is usually applied to tests to find out which
code is actually being tested and which code isn’t.&lt;/p&gt;
&lt;p&gt;Nightly Rust already supports another kind of source code coverage, commonly
called gcov, which relies on debug info to map from LLVM IR to lines of
source code. Instrumentation is then added in the LLVM backend during code
generation to count how many times each line is run.&lt;/p&gt;
&lt;p&gt;However, since LLVM doesn’t know exactly how Rust code is structured, there’s
a lot lost in the translation between Rust source and LLVM IR. Line-level
granularity is sometimes too coarse, and debug info can be unreliable,
especially when building in release mode. The result is coverage reports that
only show an approximation of what code actually executed.&lt;/p&gt;
&lt;p&gt;Source-based code coverage instrumentation is applied by the Rust compiler,
not LLVM. This instrumentation is more precise because it&#x27;s being done in
MIR, which holds a mapping between the original Rust source code and the
control-flow graph of the program.&lt;/p&gt;
&lt;p&gt;That means things like short-circuited conditionals, closures, and match
guards are all precisely counted. And since instrumentation counters are
injected as regular MIR statements, the compiler can further optimize the
program without affecting coverage results.&lt;/p&gt;
&lt;p&gt;&lt;a href&#x3D;&quot;/images/inside-rust/2020-11-12-source-based-code-coverage/comparison.png&quot;&gt;&lt;img src&#x3D;&quot;/images/inside-rust/2020-11-12-source-based-code-coverage/comparison.png&quot; alt&#x3D;&quot;Comparison of gcov and source-based coverage results&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Above: A comparison of the gcov (left) and source-based coverage (right)
results. gcov highlights skipped lines, marked with #####, while source-based
coverage highlights exact regions of code that were skipped. Note that on
line 30, one boolean subexpression is short-circuited. This is surfaced by
source-based coverage but not gcov.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;What this means is that source-based code coverage is both efficient and
accurate. LLVM’s existing coverage tools (&lt;a href&#x3D;&quot;https://llvm.org/docs/CommandGuide/llvm-profdata.html&quot;&gt;llvm-profdata&lt;/a&gt; and &lt;a href&#x3D;&quot;https://llvm.org/docs/CommandGuide/llvm-cov.html&quot;&gt;llvm-cov&lt;/a&gt;)
generate both coverage summaries and very fine-grained code regions, helping
you find gaps in your testing coverage. What you do about that is up to you!&lt;/p&gt;
&lt;h1&gt;&lt;a href&#x3D;&quot;#trying-it-out&quot; aria-hidden&#x3D;&quot;true&quot; class&#x3D;&quot;anchor&quot; id&#x3D;&quot;trying-it-out&quot;&gt;&lt;/a&gt;Trying it out&lt;/h1&gt;
&lt;p&gt;Work on the implementation &lt;a href&#x3D;&quot;https://github.com/rust-lang/compiler-team/issues/278&quot;&gt;began back in April&lt;/a&gt;, and &lt;a href&#x3D;&quot;https://github.com/rust-lang/rust/pulls?q&#x3D;is%3Apr+author%3Arichkadel+is%3Aclosed+closed%3A%3C2020-11-06&quot;&gt;many PRs
later&lt;/a&gt;, it’s ready for you to try. All you need is a recent nightly and
a tool to read the coverage reports.&lt;/p&gt;
&lt;p&gt;&lt;a href&#x3D;&quot;https://doc.rust-lang.org/nightly/unstable-book/compiler-flags/source-based-code-coverage.html&quot;&gt;Take a look at this guide to get started&lt;/a&gt;. If you spot any issues,
please &lt;a href&#x3D;&quot;https://github.com/rust-lang/rust/issues/new/choose&quot;&gt;report them&lt;/a&gt;. It’s a huge help!&lt;/p&gt;
&lt;p&gt;Finally, if you try it out and it works well, we’d also like to hear from
you! Come by the &lt;a href&#x3D;&quot;https://rust-lang.zulipchat.com/#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278&quot;&gt;Zulip stream&lt;/a&gt; for this change or comment on the &lt;a href&#x3D;&quot;https://github.com/rust-lang/rust/issues/34701&quot;&gt;feature
request&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;a href&#x3D;&quot;#acknowledgements&quot; aria-hidden&#x3D;&quot;true&quot; class&#x3D;&quot;anchor&quot; id&#x3D;&quot;acknowledgements&quot;&gt;&lt;/a&gt;Acknowledgements&lt;/h1&gt;
&lt;p&gt;The implementation work was all done by Rich Kadel; thanks to him for all the
amazing work he’s done. Thanks also to Wesley Wiser for helping with reviews,
to Bob Wilson for lending his experience with LLVM&#x27;s InstrProf coverage APIs,
and to eddyb for their guidance in choosing a MIR-based approach.&lt;/p&gt;
</content>

        <author>
            <name>Tyler Mandry</name>
        </author>
    </entry>
    
    <entry>
        <title>Exploring PGO for the Rust compiler</title>
        <link rel="alternate" href="https://blog.rust-lang.org/inside-rust/2020/11/11/exploring-pgo-for-the-rust-compiler.html" type="text/html" title="Exploring PGO for the Rust compiler" />
        <published>2020-11-11T00:00:00+00:00</published>
        <updated>2020-11-11T00:00:00+00:00</updated>
        <id>https://blog.rust-lang.org/inside-rust/2020/11/11/exploring-pgo-for-the-rust-compiler.html</id>
        <content type="html" xml:base="https://blog.rust-lang.org/inside-rust/2020/11/11/exploring-pgo-for-the-rust-compiler.html">&lt;p&gt;&lt;strong&gt;TLDR&lt;/strong&gt; -- PGO makes the compiler &lt;a href&#x3D;&quot;#final-numbers-and-a-benchmarking-plot-twist&quot;&gt;faster&lt;/a&gt; but is &lt;a href&#x3D;&quot;#where-to-go-from-here&quot;&gt;not straightforward&lt;/a&gt; to realize in CI.&lt;/p&gt;
&lt;p&gt;For the last few months Mozilla has been using Profile-Guided Optimization (PGO) to build their own &lt;a href&#x3D;&quot;https://bugzilla.mozilla.org/show_bug.cgi?id&#x3D;1326486&quot;&gt;optimized version of Clang&lt;/a&gt;, leading to an up to 9% reduction of Firefox compile times on their build infrastructure.
Would the same be possible for the Rust compiler, that is, could we apply profile-guided optimization to &lt;em&gt;rustc&lt;/em&gt; itself in order to make it faster?
This post explores exactly this question, detailing first the steps needed for generating a PGOed versions of &lt;em&gt;rustc&lt;/em&gt; (in two flavors), and then taking a look at the resulting performance implications.
But before that let&#x27;s have a little reminder what PGO even is and how it works in general.&lt;/p&gt;
&lt;h2&gt;&lt;a href&#x3D;&quot;#pgo-primer&quot; aria-hidden&#x3D;&quot;true&quot; class&#x3D;&quot;anchor&quot; id&#x3D;&quot;pgo-primer&quot;&gt;&lt;/a&gt;PGO Primer&lt;/h2&gt;
&lt;p&gt;Here is how the respective &lt;a href&#x3D;&quot;https://doc.rust-lang.org/rustc/profile-guided-optimization.html&quot;&gt;chapter from the rustc book&lt;/a&gt; describes profile-guided optimization:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The basic concept of PGO is to collect data about the typical execution of a program (e.g. which branches it is likely to take) and then use this data to inform optimizations such as inlining, machine-code layout, register allocation, etc.&lt;/p&gt;
&lt;p&gt;There are different ways of collecting data about a program&#x27;s execution. One is to run the program inside a profiler (such as perf) and another is to create an instrumented binary, that is, a binary that has data collection built into it, and run that. The latter usually provides more accurate data and it is also what is supported by &lt;code&gt;rustc&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In other words, we first generate a special, &amp;quot;instrumented&amp;quot; version of the program we want to optimize, and then use this instrumented version to generate an execution profile.
This execution profile is then used by the compiler for better optimizing the actual, final version of the program.&lt;/p&gt;
&lt;h2&gt;&lt;a href&#x3D;&quot;#how-to-apply-pgo-to-the-rust-compiler&quot; aria-hidden&#x3D;&quot;true&quot; class&#x3D;&quot;anchor&quot; id&#x3D;&quot;how-to-apply-pgo-to-the-rust-compiler&quot;&gt;&lt;/a&gt;How to apply PGO to the Rust compiler&lt;/h2&gt;
&lt;p&gt;Generating a PGOed version of &lt;em&gt;rustc&lt;/em&gt; involves the same basic steps as it does for any other kind of program:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create an instrumented version of &lt;em&gt;rustc&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Use the instrumented version of &lt;em&gt;rustc&lt;/em&gt; in order to collect profile data, i.e. compile a bunch of programs with it, ideally in a way that represents the typical use cases of the compiler.&lt;/li&gt;
&lt;li&gt;Compile the final version of &lt;em&gt;rustc&lt;/em&gt;, this time pointing the build system to the profile data we generated in the previous step.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;However, as opposed to many other programs, &lt;em&gt;rustc&lt;/em&gt; is a bit of a special case because it consists of two very large chunks of code written in different programming languages: the LLVM backend (written in C++) and the front and middle parts of the compiler (written in Rust).
Consequently, there are also two separate compilers involved in building &lt;em&gt;rustc&lt;/em&gt; -- both of which support their own version of PGO.
This complicates things slightly but fortunately the PGO setup for each of the two components can be treated in isolation.
Let&#x27;s take a look at the LLVM part first, since that is slightly simpler.&lt;/p&gt;
&lt;h3&gt;&lt;a href&#x3D;&quot;#compiling-rustcs-llvm-with-pgo&quot; aria-hidden&#x3D;&quot;true&quot; class&#x3D;&quot;anchor&quot; id&#x3D;&quot;compiling-rustcs-llvm-with-pgo&quot;&gt;&lt;/a&gt;Compiling rustc&#x27;s LLVM with PGO&lt;/h3&gt;
&lt;p&gt;PGO is a toolchain specific feature, so how it works might be different for different C++ compilers.
In this article I will only go into how it works with Clang because (a) I have no experience with PGO in other compilers, and (b) Clang is what the Rust project actually uses in production.&lt;/p&gt;
&lt;p&gt;In order to enable PGO for rustc&#x27;s LLVM we basically follow the steps laid out in the previous section.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;We make sure that our LLVM gets instrumented by applying the following changes to the &lt;code&gt;config.toml&lt;/code&gt; file in the root directory of our Rust checkout:&lt;/p&gt;
&lt;pre&gt;&lt;code class&#x3D;&quot;language-toml&quot;&gt;[llvm]

# Pass extra compiler and linker flags to the LLVM CMake build.
# &amp;lt;PROFDATA_DIR&amp;gt; must be an absolute path to a writeable
# directory, like for example /tmp/my-rustc-profdata
cflags &#x3D; &amp;quot;-fprofile-generate&#x3D;&amp;lt;PROFDATA_DIR&amp;gt;&amp;quot;
cxxflags &#x3D; &amp;quot;-fprofile-generate&#x3D;&amp;lt;PROFDATA_DIR&amp;gt;&amp;quot;

# Make sure that LLVM is built as a dylib
link-shared &#x3D; true

# Make sure we use Clang for compiling LLVM
# (assuming that we are building for x86_64 Linux in this case)
[target.x86_64-unknown-linux-gnu]
cc &#x3D; &amp;quot;clang&amp;quot;
cxx &#x3D; &amp;quot;clang++&amp;quot;
linker &#x3D; &amp;quot;clang&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;-fprofile-generate&lt;/code&gt; flag tells Clang to create an instrumented binary that will write any profile data it generates to the given directory.
It is advisable to always use an absolute path here since we don&#x27;t want things to depend on the working directory of the compiler.
We also set &lt;code&gt;link-shared &#x3D; true&lt;/code&gt; which makes sure that &lt;em&gt;rustc&lt;/em&gt;&#x27;s linker does not have to deal with linking the instrumentation runtime into C++ code.
It&#x27;s possible to make that work but it&#x27;s not worth the trouble.
Now we just need to run &lt;code&gt;./x.py build&lt;/code&gt; and wait until we have a working &lt;em&gt;rustc&lt;/em&gt; with an instrumented LLVM.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Next we collect profile data by running the compiler we built in the previous step.
This is straightforward because data collection happens completely transparently.
Just run the compiler as you always would (e.g. via Cargo) and the profile data will show up in the &lt;code&gt;&amp;lt;PROFDATA_DIR&amp;gt;&lt;/code&gt; we specified in the &lt;code&gt;-fprofile-generate&lt;/code&gt; flag above.
In order to make the collected data as useful as possible, we should try to exercise all the common code paths within the compiler.
I typically use the &amp;quot;standard&amp;quot; &lt;a href&#x3D;&quot;https://github.com/rust-lang/rustc-perf&quot;&gt;rustc-perf&lt;/a&gt; benchmark suite for this purpose, which includes debug builds, optimized builds, check builds, both incremental and non-incremental.
After this is done, you will find a number of &lt;code&gt;.profraw&lt;/code&gt; files in &lt;code&gt;&amp;lt;PROFDATA_DIR&amp;gt;&lt;/code&gt;.
&lt;a href&#x3D;&quot;https://clang.llvm.org/docs/UsersManual.html#cmdoption-fprofile-generate&quot;&gt;As described in the Clang user manual&lt;/a&gt; these &lt;code&gt;.profraw&lt;/code&gt; files need to be merged into a single &lt;code&gt;.profdata&lt;/code&gt; file by using the &lt;code&gt;llvm-profdata&lt;/code&gt; tool that comes with your Clang installation:&lt;/p&gt;
&lt;pre&gt;&lt;code class&#x3D;&quot;language-bash&quot;&gt;$ cd &amp;lt;PROFDATA_DIR&amp;gt;
$ llvm-profdata merge -output&#x3D;rustc-llvm.profdata *.profraw
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ol start&#x3D;&quot;3&quot;&gt;
&lt;li&gt;
&lt;p&gt;Now that the combined profile data from all &lt;em&gt;rustc&lt;/em&gt; invocations can be found in &lt;code&gt;&amp;lt;PROFDATA_DIR&amp;gt;/rustc-llvm.profdata&lt;/code&gt; it is time to re-compile LLVM and &lt;em&gt;rustc&lt;/em&gt; again, this time instructing Clang to make use of this valuable new information.
To this end we modify &lt;code&gt;config.toml&lt;/code&gt; as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class&#x3D;&quot;language-toml&quot;&gt;[llvm]
# Instead of -fprofile-generate, we now pass -fprofile-use to Clang
cflags &#x3D; &amp;quot;-fprofile-use&#x3D;&amp;lt;PROFDATA_DIR&amp;gt;/rustc-llvm.profdata&amp;quot;
cxxflags &#x3D; &amp;quot;-fprofile-use&#x3D;&amp;lt;PROFDATA_DIR&amp;gt;/rustc-llvm.profdata&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we make sure that LLVM is properly rebuilt by deleting the old version and build everything again:&lt;/p&gt;
&lt;pre&gt;&lt;code class&#x3D;&quot;language-bash&quot;&gt;$ cd $RUST_PROJECT_ROOT
$ rm -rf ./build/x86_64-unknown-linux-gnu/llvm
$ ./x.py build
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once this is done, we have a Rust compiler with PGO-optimized LLVM. Congratulations!&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;&lt;a href&#x3D;&quot;#pgo-optimized-llvm----benchmark-results&quot; aria-hidden&#x3D;&quot;true&quot; class&#x3D;&quot;anchor&quot; id&#x3D;&quot;pgo-optimized-llvm----benchmark-results&quot;&gt;&lt;/a&gt;PGO-optimized LLVM -- Benchmark Results&lt;/h4&gt;
&lt;p&gt;As mentioned above Firefox build times have improved by up to 9% with a PGOed compiler.
Clang&#x27;s own documentation even &lt;a href&#x3D;&quot;https://www.llvm.org/docs/HowToBuildWithPGO.html#introduction&quot;&gt;reports&lt;/a&gt; an up to 20% improvement.
The best way we have for assessing the Rust compiler&#x27;s performance is the &lt;a href&#x3D;&quot;https://github.com/rust-lang/rustc-perf&quot;&gt;rustc-perf&lt;/a&gt; benchmark suite.
Since compiling with PGO does not quite fit with how the Rust project&#x27;s CI works, we cannot use the &lt;a href&#x3D;&quot;https://perf.rust-lang.org/&quot;&gt;perf.rust-lang.org&lt;/a&gt; version of the benchmark suite.
Fortunately, thanks to &lt;a href&#x3D;&quot;https://github.com/rust-lang/rustc-perf/blob/master/collector/README.md&quot;&gt;good documentation&lt;/a&gt;, running the benchmarks locally is straightforward enough.
Here&#x27;s a glance at the effect that a PGOed LLVM has on &lt;em&gt;rustc&lt;/em&gt;&#x27;s performance:&lt;/p&gt;
&lt;p&gt;&lt;a href&#x3D;&quot;https://perf.rust-lang.org/compare.html?start&#x3D;pgo-2020-10-30-none&amp;end&#x3D;pgo-2020-10-30-llvm&amp;stat&#x3D;instructions%3Au&quot;&gt;&lt;img src&#x3D;&quot;/images/inside-rust/2020-11-11-exploring-pgo-for-the-rust-compiler/rustc-perf-pgo-llvm-thumb.png&quot; alt&#x3D;&quot;Performance improvements gained from apply PGO to LLVM&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The results are not quite as spectacular as the anecdotal 20% improvement from Clang&#x27;s documentation;
but they are pretty encouraging and show no significant performance regressions.
Diving more into details shows the expected profile:&lt;/p&gt;
&lt;p&gt;&lt;img src&#x3D;&quot;/images/inside-rust/2020-11-11-exploring-pgo-for-the-rust-compiler/rustc-perf-pgo-llvm-expanded.png&quot; alt&#x3D;&quot;Performance improvements gained from apply PGO to LLVM (details)&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Workloads that spend most of their time in LLVM (e.g. optimized builds) show the most improvement, while workloads that don&#x27;t invoke LLVM at all (e.g. check builds) also don&#x27;t profit from a faster LLVM.
Let&#x27;s take a look at how we can take things further by applying PGO to the other half of the compiler.&lt;/p&gt;
&lt;h3&gt;&lt;a href&#x3D;&quot;#applying-pgo-to-the-rust-part-of-the-compiler&quot; aria-hidden&#x3D;&quot;true&quot; class&#x3D;&quot;anchor&quot; id&#x3D;&quot;applying-pgo-to-the-rust-part-of-the-compiler&quot;&gt;&lt;/a&gt;Applying PGO to the Rust part of the compiler&lt;/h3&gt;
&lt;p&gt;The basic principle stays the same:
create an instrumented compiler, use it to collect profile data, use that data when compiling the final version of the compiler.
The only difference is that this time we instrument a different part of the compiler&#x27;s code, namely the part generated by &lt;em&gt;rustc&lt;/em&gt; itself.
The compiler has had support for doing that &lt;a href&#x3D;&quot;https://github.com/rust-lang/rust/pull/61268&quot;&gt;for a while now&lt;/a&gt; and, as can be seen in the &lt;a href&#x3D;&quot;https://doc.rust-lang.org/rustc/profile-guided-optimization.html&quot;&gt;respective chapter of the rustc book&lt;/a&gt;, the command-line interface has been modeled after Clang&#x27;s set of flags.
Unfortunately, the compiler&#x27;s build system does not support using PGO out of the box, so we have to directly modify &lt;code&gt;src/bootstrap/compile.rs&lt;/code&gt; in order to set the desired flags.
We only want to instrument the compiler itself, not the other tools or the standard library, see we add the flags to &lt;code&gt;rustc_cargo_env()&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class&#x3D;&quot;language-rust&quot;&gt;pub fn rustc_cargo_env(builder: &amp;amp;Builder&amp;lt;&#x27;_&amp;gt;,
                       cargo: &amp;amp;mut Cargo,
                       target: TargetSelection) {
    // ... omitted ...

    if builder.config.rustc_parallel {
        cargo.rustflag(&amp;quot;--cfg&#x3D;parallel_compiler&amp;quot;);
    }
    if builder.config.rust_verify_llvm_ir {
        cargo.env(&amp;quot;RUSTC_VERIFY_LLVM_IR&amp;quot;, &amp;quot;1&amp;quot;);
    }

    // This is new: Hard code instrumentation in the
    // RUSTFLAGS of the Cargo invocation that builds
    // the compiler
    cargo.rustflag(&amp;quot;-Cprofile-generate&#x3D;&amp;lt;PROFDATA_DIR&amp;gt;&amp;quot;);

    // ... omitted ...
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As before &lt;code&gt;&amp;lt;PROFDATA_DIR&amp;gt;&lt;/code&gt; must be an actual, absolute path to a directory.
Once we have collected enough profile data, we go back to &lt;code&gt;src/bootstrap/compile.rs&lt;/code&gt; and replace the &lt;code&gt;-Cprofile-generate&lt;/code&gt; flag with a &lt;code&gt;-Cprofile-use&lt;/code&gt; flag:&lt;/p&gt;
&lt;pre&gt;&lt;code class&#x3D;&quot;language-rust&quot;&gt;pub fn rustc_cargo_env(builder: &amp;amp;Builder&amp;lt;&#x27;_&amp;gt;,
                       cargo: &amp;amp;mut Cargo,
                       target: TargetSelection) {
    // ... omitted ...

    if builder.config.rustc_parallel {
        cargo.rustflag(&amp;quot;--cfg&#x3D;parallel_compiler&amp;quot;);
    }
    if builder.config.rust_verify_llvm_ir {
        cargo.env(&amp;quot;RUSTC_VERIFY_LLVM_IR&amp;quot;, &amp;quot;1&amp;quot;);
    }

    // Replace &#x60;-Cprofile-generate&#x60; with &#x60;-Cprofile-use&#x60;,
    // assuming that we used the &#x60;llvm-profdata&#x60; tool to
    // merge the collected &#x60;&amp;lt;PROFDATA_DIR&amp;gt;/*.profraw&#x60; files
    // into a common file named
    // &#x60;&amp;lt;PROFDATA_DIR&amp;gt;/rustc-rust.profdata&#x60;.
    cargo.rustflag(
        &amp;quot;-Cprofile-use&#x3D;&amp;lt;PROFDATA_DIR&amp;gt;/rustc-rust.profdata&amp;quot;
    );

    // ... omitted ...
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&#x27;s take a look at the effects PGO has on this portion of the compiler.&lt;/p&gt;
&lt;h4&gt;&lt;a href&#x3D;&quot;#pgo-optimized-rust----benchmark-results&quot; aria-hidden&#x3D;&quot;true&quot; class&#x3D;&quot;anchor&quot; id&#x3D;&quot;pgo-optimized-rust----benchmark-results&quot;&gt;&lt;/a&gt;PGO-optimized Rust -- Benchmark Results&lt;/h4&gt;
&lt;p&gt;As expected the results are similar to when PGO was applied to LLVM: a reduction of instruction counts by roughly 5%. NOTE: These numbers show the improvement from applying PGO &lt;em&gt;exclusively&lt;/em&gt; to the Rust part of the compiler. The LLVM part was &lt;em&gt;not&lt;/em&gt; compiled with PGO here:&lt;/p&gt;
&lt;p&gt;&lt;a href&#x3D;&quot;https://perf.rust-lang.org/compare.html?start&#x3D;pgo-2020-10-30-none&amp;end&#x3D;pgo-2020-10-30-rust&amp;stat&#x3D;instructions%3Au&quot;&gt;&lt;img src&#x3D;&quot;/images/inside-rust/2020-11-11-exploring-pgo-for-the-rust-compiler/rustc-perf-pgo-rust-thumb.png&quot; alt&#x3D;&quot;Performance improvements gained from applying PGO to (only) the Rust part of the compiler&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Because different workloads execute different amounts of Rust code (vs C++/LLVM code), the total reduction can be a lot less for LLVM-heavy cases.
For example, a full &lt;em&gt;webrender-opt&lt;/em&gt; build will spend more than 80% of its time in LLVM, so reducing the remaining 20% by 5% can only reduce the total number by 1%.
On the other hand, a &lt;em&gt;check&lt;/em&gt; build or an &lt;em&gt;incr-unchanged&lt;/em&gt; build spends almost no time in LLVM, so the 5% Rust performance improvement translates almost entirely into a 5% instruction count reduction for these cases:&lt;/p&gt;
&lt;p&gt;&lt;img src&#x3D;&quot;/images/inside-rust/2020-11-11-exploring-pgo-for-the-rust-compiler/rustc-perf-pgo-rust-expanded.png&quot; alt&#x3D;&quot;Performance improvements gained from applying PGO to (only) the Rust part of the compiler (details)&quot; /&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a href&#x3D;&quot;#can-we-apply-pgo-to-rust-and-llvm-at-the-same-time&quot; aria-hidden&#x3D;&quot;true&quot; class&#x3D;&quot;anchor&quot; id&#x3D;&quot;can-we-apply-pgo-to-rust-and-llvm-at-the-same-time&quot;&gt;&lt;/a&gt;Can we apply PGO to Rust and LLVM at the same time?&lt;/h3&gt;
&lt;p&gt;The short answer is &lt;em&gt;yes&lt;/em&gt;.
The longer answer is that we have to be careful about profile data incompatibilities.
Both Clang and the Rust compiler use the same LLVM-based PGO mechanisms underneath.
If both Clang and the Rust compiler use the exact same version of LLVM, we can even combine the two into a single &lt;code&gt;.profdata&lt;/code&gt; file.
However, if the two LLVM versions are different, we better make sure that the two compilers don&#x27;t get into each other&#x27;s way.
Luckily it&#x27;s straightforward to facilitate that:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;We need to specify different directories for the respective &lt;code&gt;-fprofile-generate&lt;/code&gt; and &lt;code&gt;-Cprofile-generate&lt;/code&gt; (and &lt;code&gt;*-use&lt;/code&gt;) flags.
This way the instrumentation code coming from Clang will write into one directory and the code coming from &lt;em&gt;rustc&lt;/em&gt; will write into another.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We need to make sure that we use the right &lt;code&gt;llvm-profdata&lt;/code&gt; tool for each set of &lt;code&gt;.profraw&lt;/code&gt; files.
Use the one coming with Clang for handling the files in the Clang directory and the one coming with the Rust compiler for the files in the Rust directory.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If we do that, we get a compiler with both parts optimized via PGO, with the compile time reductions adding up nicely.&lt;/p&gt;
&lt;h3&gt;&lt;a href&#x3D;&quot;#final-numbers-and-a-benchmarking-plot-twist&quot; aria-hidden&#x3D;&quot;true&quot; class&#x3D;&quot;anchor&quot; id&#x3D;&quot;final-numbers-and-a-benchmarking-plot-twist&quot;&gt;&lt;/a&gt;Final Numbers and a Benchmarking Plot Twist&lt;/h3&gt;
&lt;p&gt;When I looked at the &lt;a href&#x3D;&quot;https://perf.rust-lang.org/compare.html?start&#x3D;pgo-2020-10-30-none&amp;end&#x3D;pgo-2020-10-30-both&amp;stat&#x3D;instructions%3Au&quot;&gt;the final numbers&lt;/a&gt;, I was a bit underwhelmed.
Sure, PGO seems to lead to a pretty solid 5% reduction of instruction counts across basically all real world workloads in the benchmark suite, for &lt;em&gt;check&lt;/em&gt;, &lt;em&gt;debug&lt;/em&gt;, and &lt;em&gt;opt&lt;/em&gt; builds alike.
That is pretty nice -- but also far away from the 20% improvement mentioned in the Clang documentation.
Given that PGO adds quite a few complications to the build process of the compiler itself (not to mention the almost tripled build times) I started to think that applying PGO to the compiler would probably not be worth the trouble.&lt;/p&gt;
&lt;p&gt;I then took a glance at the benchmarks&#x27; wall time measurements (instead of the instruction count measurements) and saw quite a different picture: &lt;em&gt;webrender-opt&lt;/em&gt; minus 15%, &lt;em&gt;style-servo-opt&lt;/em&gt; minus 14%, &lt;em&gt;serde-check&lt;/em&gt; minus 15%?
This looked decidedly better than for instruction counts.
But wall time measurements can be very noisy (which is why most people only look at instruction counts on perf.rust-lang.org), and &lt;code&gt;rustc-perf&lt;/code&gt; only does a single iteration for each benchmark, so I was not prepared to trust these numbers just yet.
I decided to try and reduce the noise by increasing the number of benchmark iterations from one to twenty.
I only did &amp;quot;full&amp;quot; builds in this configuration as PGO&#x27;s effect seemed to translate pretty predictably to incremental builds.
After roughly eight hours to complete both the PGO and the non-PGO versions of the benchmarks these are the numbers I got:&lt;/p&gt;
&lt;p&gt;&lt;a href&#x3D;&quot;https://perf.rust-lang.org/compare.html?start&#x3D;pgo-2020-10-30-none-20&amp;end&#x3D;pgo-2020-10-30-both-20&amp;stat&#x3D;wall-time&quot;&gt;&lt;img src&#x3D;&quot;/images/inside-rust/2020-11-11-exploring-pgo-for-the-rust-compiler/rustc-perf-pgo-both-walltime-thumb.png&quot; alt&#x3D;&quot;Wall time improvements gained from applying PGO to the entire compiler&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;As you can see we get a 10-16% reduction of build times almost across the board for real world test cases.
This was more in line with what I had initially hoped to get from PGO.
It is a bit surprising that the difference between instruction counts and wall time is so pronounced.
One plausible explanation would be that PGO improves instruction cache utilization, something which makes a difference for execution time but would not be reflected in the amount of instructions executed.
I also don&#x27;t know how branch mispredictions factor into instruction counts -- branch prediction being another aspect explicitly targeted by PGO.&lt;/p&gt;
&lt;p&gt;As good as these numbers look, please keep in mind that they come from a single machine.
It&#x27;s possible that the Ryzen 1700X processor I used has some idiosyncrasies that favor the kind of optimizations that PGO does, and a different processor with a different caching system and branch predictor would generate quite different numbers.
Nonetheless, the numbers undoubtedly are very encouraging and warrant further investigation.&lt;/p&gt;
&lt;h2&gt;&lt;a href&#x3D;&quot;#where-to-go-from-here&quot; aria-hidden&#x3D;&quot;true&quot; class&#x3D;&quot;anchor&quot; id&#x3D;&quot;where-to-go-from-here&quot;&gt;&lt;/a&gt;Where to go from here&lt;/h2&gt;
&lt;p&gt;The numbers above suggest that PGO can indeed provide noticeable compile time reductions.
Unfortunately, bringing these improvements to end users is not as simple as adding a few compiler flags to our &lt;a href&#x3D;&quot;https://github.com/rust-lang/rust/tree/master/src/ci/docker/host-x86_64&quot;&gt;dist builds&lt;/a&gt;.
PGO is different from most other optimizations in that it&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;requires a different, extended build workflow due to the additional instrumentation and data collection phases, and&lt;/li&gt;
&lt;li&gt;it incurs a sustained build time cost (a trait it shares with other automated optimizations like LTO).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Both of these problems pose substantial hurdles for actually using PGO on the compiler itself.
Rust&#x27;s CI build times have always been too long and we already forgo some optimizations because of them
(e.g. macOS still does not get the 10% performance boost from using a ThinLTOed LLVM because the build machines on that platform are especially slow).
However, I think there&#x27;s still a way forward. There&#x27;s a tradeoff between the two obstacles mentioned above:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If build times are not a problem, then the engineering effort for supporting PGO in the compiler&#x27;s build system is quite low.
That is, if it is OK for instrumentation, data collection, and final build to all occur as a single monolithic build on the same machine then it should be straightforward to extend the build system to support just that.&lt;/li&gt;
&lt;li&gt;If a lot of engineering effort is put into a more complicated build setup, with out-of-band instrumentation and caching of profile data, then the impact on build times can be kept quite low.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I estimate that the first approach is more fruitful, as it is always better to put more value on low engineering and maintenance costs than on low compute times.
Having a straightforward way of obtaining a PGOed compiler (e.g. by adding a simple setting in &lt;code&gt;config.toml&lt;/code&gt;) would unblock the path to a couple of scenarios:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Organizations and individuals who don&#x27;t switch compiler versions too frequently can easily compile their own, optimized version of &lt;em&gt;rustc&lt;/em&gt; for internal use, like Mozilla is already doing with Clang.
Letting a computer spend a couple of hours in order to get a 15% compile time reduction for the next couple of months seems like a good investment.&lt;/li&gt;
&lt;li&gt;The Rust project itself could start thinking about providing more optimized builds, at least on the beta and stable channels.
Significantly increasing the compiler&#x27;s build times on the official build infrastructure is a lot more viable if it only has to be done every six weeks instead of for every merged pull request.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It&#x27;s unlikely that I can spend a lot of time on this personally -- but my hope is that others will pick up the baton. I&#x27;d be happy to provide guidance on how to use PGO specifically.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;PS&lt;/strong&gt; -- Special thanks to Mark Rousskov for uploading my local benchmarking data to &lt;a href&#x3D;&quot;https://perf.rust-lang.org/compare.html?start&#x3D;pgo-2020-10-30-none-20&amp;end&#x3D;pgo-2020-10-30-both-20&amp;stat&#x3D;wall-time&quot;&gt;perf.rust-lang.org&lt;/a&gt;, which makes it much nicer to explore!&lt;/p&gt;
</content>

        <author>
            <name>Michael Woerister</name>
        </author>
    </entry>
    
    <entry>
        <title>Core team membership changes</title>
        <link rel="alternate" href="https://blog.rust-lang.org/inside-rust/2020/10/23/Core-team-membership.html" type="text/html" title="Core team membership changes" />
        <published>2020-10-23T00:00:00+00:00</published>
        <updated>2020-10-23T00:00:00+00:00</updated>
        <id>https://blog.rust-lang.org/inside-rust/2020/10/23/Core-team-membership.html</id>
        <content type="html" xml:base="https://blog.rust-lang.org/inside-rust/2020/10/23/Core-team-membership.html">&lt;p&gt;The core team has had a few membership updates in the last month, and we wanted to provide an update.&lt;/p&gt;
&lt;p&gt;To start, Florian Gilcher is joining the Core team as a full member. Florian has been attending meetings as an observer since March 2019. He is the lead of the Community Events team, and has done a lot of work in the open source world, with plenty of insight to offer especially as we look to form a Rust Foundation.&lt;/p&gt;
&lt;p&gt;There are also two folks stepping back from the team. Carol Nichols has been a member of the team for three years, and she is stepping back to make more time for other projects in the community, including crates.io and her continued work on the Rust book. Nick Cameron &lt;a href&#x3D;&quot;https://www.ncameron.org/blog/leaving-the-rust-core-team/&quot;&gt;has recently welcomed a second child&lt;/a&gt; (congratulations!) and is leaving the core team to be able to focus more on his family and his work at PingCAP. He will continue to be around in the Rust community. Thanks to both Carol and Nick for their hard work over the years — we’ll miss you!&lt;/p&gt;
</content>

        <author>
            <name>Mark Rousskov</name>
        </author>
    </entry>
    
    <entry>
        <title>Lang team Backlog Bonanza and Project Proposals</title>
        <link rel="alternate" href="https://blog.rust-lang.org/inside-rust/2020/10/16/Backlog-Bonanza.html" type="text/html" title="Lang team Backlog Bonanza and Project Proposals" />
        <published>2020-10-16T00:00:00+00:00</published>
        <updated>2020-10-16T00:00:00+00:00</updated>
        <id>https://blog.rust-lang.org/inside-rust/2020/10/16/Backlog-Bonanza.html</id>
        <content type="html" xml:base="https://blog.rust-lang.org/inside-rust/2020/10/16/Backlog-Bonanza.html">&lt;p&gt;A month or two back, the lang team embarked on a new initiative that
we call the &amp;quot;Backlog Bonanza&amp;quot;. The idea is simple: we are holding a
series of meetings in which we go through every pending RFC, one by
one, and try to reach some sort of determination about what to do with
it.  Once we&#x27;ve finished that, we can start in on categorizing other
forms of backlog, such as tracking issues.&lt;/p&gt;
&lt;h3&gt;&lt;a href&#x3D;&quot;#possible-outcomes-for-each-rfc&quot; aria-hidden&#x3D;&quot;true&quot; class&#x3D;&quot;anchor&quot; id&#x3D;&quot;possible-outcomes-for-each-rfc&quot;&gt;&lt;/a&gt;Possible outcomes for each RFC&lt;/h3&gt;
&lt;p&gt;When we look at an RFC, we&#x27;re typically deciding between one of the following outcomes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Close&lt;/strong&gt; the RFC, if the problem doesn&#x27;t seem like high priority at the moment, or the solution seems quite far from what we would want.&lt;/li&gt;
&lt;li&gt;Close, but &lt;strong&gt;suggest a &lt;a href&#x3D;&quot;https://lang-team.rust-lang.org/proposing_a_project.html&quot;&gt;project proposal&lt;/a&gt;&lt;/strong&gt;, if we think that the we might like to see the problem solved, but we aren&#x27;t sure if the RFC has the design right, or we&#x27;re not sure who would be a good liaison.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Merge&lt;/strong&gt; the RFC, if we think the RFC basically nailed it and we have a lang team liaison in mind.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a href&#x3D;&quot;#wait-what-is-a-project-proposal&quot; aria-hidden&#x3D;&quot;true&quot; class&#x3D;&quot;anchor&quot; id&#x3D;&quot;wait-what-is-a-project-proposal&quot;&gt;&lt;/a&gt;Wait, what is a project proposal?&lt;/h3&gt;
&lt;p&gt;I&#x27;m so glad you asked! The lang team is experimenting with a new
process for extending the language. Instead of starting out by writing
an RFC, the idea is to start with a &lt;strong&gt;&lt;a href&#x3D;&quot;https://lang-team.rust-lang.org/proposing_a_project.html&quot;&gt;project proposal&lt;/a&gt;&lt;/strong&gt;. This is a
lightweight description that you do by &lt;a href&#x3D;&quot;https://github.com/rust-lang/lang-team/issues/new/choose&quot;&gt;opening an issue&lt;/a&gt; on the
&lt;a href&#x3D;&quot;https://github.com/rust-lang/lang-team/&quot;&gt;lang-team repository&lt;/a&gt; using the &amp;quot;Project proposal&amp;quot; template. That
will create an issue and a corresponding stream on Zulip.&lt;/p&gt;
&lt;p&gt;In our &lt;a href&#x3D;&quot;https://lang-team.rust-lang.org/meetings.html&quot;&gt;weekly triage meetings&lt;/a&gt;, we go over each new project proposal
and try to provide feedback. Project proposals generally result in one
of a few possible outcomes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Close&lt;/strong&gt;, if we feel like the idea isn&#x27;t a good fit right now.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Suggest implementing&lt;/strong&gt;, if we feel like the idea is simple or obvious enough that an RFC isn&#x27;t really needed. In that case, folks can just write a PR and we can use the fcp process to approve the PR.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Charter a project group&lt;/strong&gt;, if we feel like the idea is good, but we&#x27;d like to see the design spelled out. To do this, there has to be some lang-team liaison who wants to help see it through (though that liaison doesn&#x27;t have to be a member of the team; &lt;a href&#x3D;&quot;https://blog.rust-lang.org/inside-rust/2020/07/09/lang-team-path-to-membership.html&quot;&gt;serving as a liaison is a good way to get more involved in the lang team&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a href&#x3D;&quot;#chartering-a-project-group&quot; aria-hidden&#x3D;&quot;true&quot; class&#x3D;&quot;anchor&quot; id&#x3D;&quot;chartering-a-project-group&quot;&gt;&lt;/a&gt;Chartering a project group&lt;/h3&gt;
&lt;p&gt;A &amp;quot;project group&amp;quot; is basically just a group of people working together
completing some idea. Project groups are often pretty small, just 1 or 2
people, though they can get significantly larger.&lt;/p&gt;
&lt;p&gt;Creating a smaller project group is meant to be lightweight. We
basically convert the project proposal into a charter that states the
general goals and create an associated zulip stream where folks can
chat. Each project also gets a tracking issue that shows up on our
&lt;a href&#x3D;&quot;https://github.com/rust-lang/lang-team/projects/2&quot;&gt;lang team project board&lt;/a&gt;. (For larger project groups, we can make a
dedicated repo and an entry in the &lt;a href&#x3D;&quot;https://github.com/rust-lang/team&quot;&gt;Rust team repo&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;In the early stages of an idea, project groups work to draft an
RFC. This RFC is then taken to the lang-team for feedback. Once the
lang-team is basically happy on the direction things are going, we&#x27;ll
encourage the group to open the RFC on the main RFC repository, where
it&#x27;ll get feedback from a broader audience.&lt;/p&gt;
&lt;p&gt;Once the RFC is &lt;strong&gt;accepted&lt;/strong&gt;, the hope is that project groups stick
around. If desired, the same folks can try to implement the feature
(in collaboration with the compiler team) or we can find new people.
But this way, as those people try to implement, they&#x27;ll become a part
of the same group that was designing the feature so that we can
iterate more readily. The same logic applies to the other aspects of
shipping a feature, most notably writing documentation.&lt;/p&gt;
&lt;h3&gt;&lt;a href&#x3D;&quot;#tracking-projects-the-lang-team-project-board&quot; aria-hidden&#x3D;&quot;true&quot; class&#x3D;&quot;anchor&quot; id&#x3D;&quot;tracking-projects-the-lang-team-project-board&quot;&gt;&lt;/a&gt;Tracking projects: the lang team project board&lt;/h3&gt;
&lt;p&gt;I mentioned the &lt;a href&#x3D;&quot;https://github.com/rust-lang/lang-team/projects/2&quot;&gt;lang team project board&lt;/a&gt; off-hand in the previous
paragraph. This is our attempt to track the ongoing efforts. It breaks
down the various projects into stages, with the things that are closest
to shipping coming first:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Stabilization&lt;/strong&gt; -- projects that we are ready to stabilize, or in
the process of stabilizing.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Evaluation&lt;/strong&gt; -- projects that are fully implemented but where we are
seeking feedback on how well the design works.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Implementation&lt;/strong&gt; -- projects that are currently working on implementation
(and sometimes concurrent design iteration).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pending RFC&lt;/strong&gt; -- projects with an RFC that is pending public comment&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Design&lt;/strong&gt; -- projects actively iterating towards an RFC&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Shortlisted&lt;/strong&gt; -- project ideas that we might want to take up once we
find a suitable liaison or people have enough bandwidth&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a href&#x3D;&quot;#ways-to-get-involved&quot; aria-hidden&#x3D;&quot;true&quot; class&#x3D;&quot;anchor&quot; id&#x3D;&quot;ways-to-get-involved&quot;&gt;&lt;/a&gt;Ways to get involved&lt;/h3&gt;
&lt;p&gt;If you like, you are welcome to attend backlog bonanza meetings. They
are open for anyone and take place during our &lt;a href&#x3D;&quot;https://lang-team.rust-lang.org/meetings.html&quot;&gt;design meeting&lt;/a&gt;
most weeks. We haven&#x27;t setup a very good process for announcing our
design meeting schedule, though, that&#x27;s something that we need to get
better at.&lt;/p&gt;
&lt;p&gt;Alternatively, if you have ideas you&#x27;d like to float, please feel free
to open a &lt;a href&#x3D;&quot;https://lang-team.rust-lang.org/proposing_a_project.html&quot;&gt;project proposal&lt;/a&gt;.&lt;/p&gt;
</content>

        <author>
            <name>Nicholas Matsakis</name>
        </author>
    </entry>
    
    <entry>
        <title>1.47.0 second pre-release testing</title>
        <link rel="alternate" href="https://blog.rust-lang.org/inside-rust/2020/10/07/1.47.0-prerelease-2.html" type="text/html" title="1.47.0 second pre-release testing" />
        <published>2020-10-07T00:00:00+00:00</published>
        <updated>2020-10-07T00:00:00+00:00</updated>
        <id>https://blog.rust-lang.org/inside-rust/2020/10/07/1.47.0-prerelease-2.html</id>
        <content type="html" xml:base="https://blog.rust-lang.org/inside-rust/2020/10/07/1.47.0-prerelease-2.html">&lt;p&gt;The second pre-release for 1.47.0 is ready for testing. The release is
scheduled for this Thursday, October 8th. &lt;a href&#x3D;&quot;https://github.com/rust-lang/rust/blob/stable/RELEASES.md#version-1470-2020-10-08&quot;&gt;Release notes can be found
here.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You can try it out locally by running:&lt;/p&gt;
&lt;pre&gt;&lt;code class&#x3D;&quot;language-plain&quot;&gt;RUSTUP_DIST_SERVER&#x3D;https://dev-static.rust-lang.org rustup update stable
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The index is &lt;a href&#x3D;&quot;https://dev-static.rust-lang.org/dist/2020-10-07/index.html&quot;&gt;https://dev-static.rust-lang.org/dist/2020-10-07/index.html&lt;/a&gt;. You
can leave feedback on the &lt;a href&#x3D;&quot;https://internals.rust-lang.org/t/1-47-0-pre-release-testing/&quot;&gt;internals thread&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Compared to the first pre-release, this one contains a fix for issue &lt;a href&#x3D;&quot;https://github.com/rust-lang/rust/issues/76980&quot;&gt;#76980&lt;/a&gt;,
the last known regression of 1.47.0. We&#x27;re interested in additional testing of
this pre-release, as it includes that last-minute change.&lt;/p&gt;
</content>

        <author>
            <name>Pietro Albini</name>
        </author>
    </entry>
    
    <entry>
        <title>1.47.0 pre-release testing</title>
        <link rel="alternate" href="https://blog.rust-lang.org/inside-rust/2020/10/06/1.47.0-prerelease.html" type="text/html" title="1.47.0 pre-release testing" />
        <published>2020-10-06T00:00:00+00:00</published>
        <updated>2020-10-06T00:00:00+00:00</updated>
        <id>https://blog.rust-lang.org/inside-rust/2020/10/06/1.47.0-prerelease.html</id>
        <content type="html" xml:base="https://blog.rust-lang.org/inside-rust/2020/10/06/1.47.0-prerelease.html">&lt;p&gt;The 1.47.0 pre-release is ready for testing. The release is scheduled for this
Thursday, October 8th. &lt;a href&#x3D;&quot;https://github.com/rust-lang/rust/blob/stable/RELEASES.md#version-1470-2020-10-08&quot;&gt;Release notes can be found here.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You can try it out locally by running:&lt;/p&gt;
&lt;pre&gt;&lt;code class&#x3D;&quot;language-plain&quot;&gt;RUSTUP_DIST_SERVER&#x3D;https://dev-static.rust-lang.org rustup update stable
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The index is &lt;a href&#x3D;&quot;https://dev-static.rust-lang.org/dist/2020-10-06/index.html&quot;&gt;https://dev-static.rust-lang.org/dist/2020-10-06/index.html&lt;/a&gt;. You
can leave feedback on the &lt;a href&#x3D;&quot;https://internals.rust-lang.org/t/1-47-0-pre-release-testing/&quot;&gt;internals thread&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Additionally, the release team is still investigating a regression in procedural
macros which include C++ code, &lt;a href&#x3D;&quot;https://github.com/rust-lang/rust/issues/76980&quot;&gt;#76980&lt;/a&gt;, and are interested in feedback and help
from the community in figuring out a resolution to that bug.&lt;/p&gt;
</content>

        <author>
            <name>Mark Rousskov</name>
        </author>
    </entry>
    
    <entry>
        <title>Announcing the Portable SIMD Project Group</title>
        <link rel="alternate" href="https://blog.rust-lang.org/inside-rust/2020/09/29/Portable-SIMD-PG.html" type="text/html" title="Announcing the Portable SIMD Project Group" />
        <published>2020-09-29T00:00:00+00:00</published>
        <updated>2020-09-29T00:00:00+00:00</updated>
        <id>https://blog.rust-lang.org/inside-rust/2020/09/29/Portable-SIMD-PG.html</id>
        <content type="html" xml:base="https://blog.rust-lang.org/inside-rust/2020/09/29/Portable-SIMD-PG.html">&lt;p&gt;We&#x27;re announcing the start of the &lt;em&gt;Portable SIMD Project Group&lt;/em&gt; within the Libs team. This group is dedicated to making a portable SIMD API available to stable Rust users.&lt;/p&gt;
&lt;p&gt;The Portable SIMD Project Group is lead by &lt;a href&#x3D;&quot;https://github.com/calebzulawski&quot;&gt;@calebzulawski&lt;/a&gt;, &lt;a href&#x3D;&quot;https://github.com/Lokathor&quot;&gt;@Lokathor&lt;/a&gt;, and &lt;a href&#x3D;&quot;https://github.com/workingjubilee&quot;&gt;@workingjubilee&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a href&#x3D;&quot;#what-are-project-groups&quot; aria-hidden&#x3D;&quot;true&quot; class&#x3D;&quot;anchor&quot; id&#x3D;&quot;what-are-project-groups&quot;&gt;&lt;/a&gt;What are project groups?&lt;/h2&gt;
&lt;p&gt;Rust uses &lt;a href&#x3D;&quot;https://rust-lang.github.io/rfcs/2856-project-groups.html&quot;&gt;project groups&lt;/a&gt; to help coordinate work.
They&#x27;re a place for people to get involved in helping shape the parts of Rust that matter to them.&lt;/p&gt;
&lt;h2&gt;&lt;a href&#x3D;&quot;#what-is-simd&quot; aria-hidden&#x3D;&quot;true&quot; class&#x3D;&quot;anchor&quot; id&#x3D;&quot;what-is-simd&quot;&gt;&lt;/a&gt;What is SIMD?&lt;/h2&gt;
&lt;p&gt;SIMD stands for Single Instruction, Multiple Data.
It lets the CPU apply a single instruction to a &amp;quot;vector&amp;quot; of data.
The vector is a single extra-wide CPU register made of multiple &amp;quot;lanes&amp;quot; of the same data type.
You can think of it as being &lt;em&gt;similar&lt;/em&gt; to an array.
Instead of processing each lane individually, all lanes have the same operation applied &lt;em&gt;simultaneously&lt;/em&gt;.
This lets you transform data much faster than with standard code.
Not every problem can be accelerated with &amp;quot;vectorized&amp;quot; code, but for multimedia and list-processing applications there can be significant gains.&lt;/p&gt;
&lt;h2&gt;&lt;a href&#x3D;&quot;#why-do-you-need-to-make-it-portable&quot; aria-hidden&#x3D;&quot;true&quot; class&#x3D;&quot;anchor&quot; id&#x3D;&quot;why-do-you-need-to-make-it-portable&quot;&gt;&lt;/a&gt;Why do you need to make it portable?&lt;/h2&gt;
&lt;p&gt;Different chip vendors offer different SIMD instructions.
Some of these are available in Rust&#x27;s &lt;a href&#x3D;&quot;https://doc.rust-lang.org/core/arch/index.html&quot;&gt;&lt;code&gt;std::arch&lt;/code&gt;&lt;/a&gt; module.
You &lt;em&gt;can&lt;/em&gt; build vectorized functions using that, but at the cost of maintaining a different version for each CPU you want to support.
You can also &lt;em&gt;not&lt;/em&gt; write vectorized operations and hope that LLVM&#x27;s optimizations will &amp;quot;auto-vectorize&amp;quot; your code.
However, the auto-vectorizer is easily confused and can fail to optimize &amp;quot;obvious&amp;quot; vector tasks.&lt;/p&gt;
&lt;p&gt;The portable SIMD API will enable writing SIMD code just once using a high-level API.
By explicitly communicating your intent to the compiler, it&#x27;s better able to generate the best possible final code.
This is still only a best-effort process.
If your target doesn&#x27;t support a desired operation in SIMD, the compiler will fall back to using scalar code, processing one lane at a time.
The details of what&#x27;s available depend on the build target.&lt;/p&gt;
&lt;p&gt;We intend to release the Portable SIMD API as &lt;code&gt;std::simd&lt;/code&gt;.
We will cover as many use cases as we can, but it might still be appropriate for you to use &lt;code&gt;std::arch&lt;/code&gt; directly.
For that reason the &lt;code&gt;std::simd&lt;/code&gt; types will also be easily convertable to &lt;code&gt;std::arch&lt;/code&gt; types where needed.&lt;/p&gt;
&lt;h2&gt;&lt;a href&#x3D;&quot;#how-can-i-get-involved&quot; aria-hidden&#x3D;&quot;true&quot; class&#x3D;&quot;anchor&quot; id&#x3D;&quot;how-can-i-get-involved&quot;&gt;&lt;/a&gt;How can I get involved?&lt;/h2&gt;
&lt;p&gt;Everyone can get involved!
No previous experience necessary.
If you&#x27;d like to help make portable SIMD a reality you can visit our &lt;a href&#x3D;&quot;https://github.com/rust-lang/project-portable-simd&quot;&gt;GitHub repository&lt;/a&gt; or reach out on &lt;a href&#x3D;&quot;https://rust-lang.zulipchat.com/#narrow/stream/257879-project-portable-simd&quot;&gt;Zulip&lt;/a&gt; and say hi! :wave:&lt;/p&gt;
</content>

        <author>
            <name>Jubilee and Lokathor</name>
        </author>
    </entry>
    
    <entry>
        <title>Announcing the Error Handling Project Group</title>
        <link rel="alternate" href="https://blog.rust-lang.org/inside-rust/2020/09/18/error-handling-wg-announcement.html" type="text/html" title="Announcing the Error Handling Project Group" />
        <published>2020-09-18T00:00:00+00:00</published>
        <updated>2020-09-18T00:00:00+00:00</updated>
        <id>https://blog.rust-lang.org/inside-rust/2020/09/18/error-handling-wg-announcement.html</id>
        <content type="html" xml:base="https://blog.rust-lang.org/inside-rust/2020/09/18/error-handling-wg-announcement.html">&lt;p&gt;Today we are announcing the formation of a new project group under
the libs team, focused on error handling!&lt;/p&gt;
&lt;p&gt;Some of the goals this project group will be working on include:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Defining and codifying common error handling terminology.&lt;/li&gt;
&lt;li&gt;Generating consensus on current error handling best practices.&lt;/li&gt;
&lt;li&gt;Identifying pain points that exist in Rust’s error handling story.&lt;/li&gt;
&lt;li&gt;Communicating current error handling best practices.&lt;/li&gt;
&lt;li&gt;Consolidating the Rust error handling ecosystem.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This new project group is being shepherded by Jane Lusby
(&lt;a href&#x3D;&quot;https://github.com/yaahc&quot;&gt;@yaahc&lt;/a&gt;) and Sean Chen
(&lt;a href&#x3D;&quot;https://github.com/seanchen1991&quot;&gt;@seanchen1991&lt;/a&gt;), with Andrew
Gallant (&lt;a href&#x3D;&quot;https://github.com/burntsushi&quot;&gt;@BurntSushi&lt;/a&gt;) acting in
an advisory capacity and Ashley Mannix
(&lt;a href&#x3D;&quot;https://github.com/KodrAus&quot;&gt;@KodrAus&lt;/a&gt;) acting as the library team
liaison.&lt;/p&gt;
&lt;p&gt;Anyone interested in helping out with the above goals is invited to
come say hi in the group’s  &lt;a href&#x3D;&quot;https://rust-lang.zulipchat.com/#narrow/stream/257204-project-error-handling&quot;&gt;Zulip stream&lt;/a&gt;. Feel free to also check
out the group’s &lt;a href&#x3D;&quot;https://github.com/rust-lang/project-error-handling&quot;&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt;
</content>

        <author>
            <name>Sean Chen</name>
        </author>
    </entry>
    
</feed>
